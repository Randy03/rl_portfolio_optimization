{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c6a8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import gym\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import random\n",
    "from joblib import dump,load\n",
    "import datetime\n",
    "import pandas_datareader.data as wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3fc58952",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioBuffer():\n",
    "    def __init__(self,assets_names_list,assets_data_list,window):\n",
    "        self.names = {0:'CASH'}\n",
    "        for index,value in enumerate(assets_data_list):\n",
    "            self.names[index+1] = value\n",
    "        self.shape = assets_data_list[0].shape\n",
    "        for i in assets_data_list:\n",
    "            if self.shape != i.shape:\n",
    "                raise Exception('Data must be of the same size')\n",
    "        if len(assets_data_list) != len(assets_names_list):\n",
    "            raise Exception('The length of assets_names_list is different than the amount of assets in assets_data_list')\n",
    "        self.data = np.array([np.ones(shape=self.shape)] + assets_data_list)\n",
    "        self.shape = self.data.shape\n",
    "        self.pointer = window\n",
    "        self.window = window\n",
    "        self.batch_cache = None\n",
    "        self.length = self.shape[1]\n",
    "    \n",
    "    def get_batch(self):\n",
    "        if not self.batch_cache:\n",
    "            batch = np.zeros(shape=(self.shape[0],self.window,self.shape[2]))\n",
    "            for index,data in enumerate(self.data):\n",
    "                batch[index] = data[self.pointer-self.window:self.pointer]/data[self.pointer-1][0]\n",
    "            self.batch_cache = batch\n",
    "        return self.batch_cache\n",
    "    \n",
    "    def get_next_batch(self):\n",
    "        self.pointer += 1\n",
    "        self.batch_cache = None\n",
    "        return self.get_batch()\n",
    "    \n",
    "    def get_current_price(self,index):\n",
    "        return self.data[index][pointer-1][0]\n",
    "    \n",
    "    def reset(self):\n",
    "        self.pointer = self.window\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1652d128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 58, 3)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google = pd.read_csv('GOOG.csv')[['Adj Close','High','Low']]\n",
    "xom = pd.read_csv('XOM.csv')[['Adj Close','High','Low']]\n",
    "assets_data_list = [google.to_numpy(),xom.to_numpy(),xom.to_numpy()]\n",
    "data = np.array(assets_data_list)\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ed6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioEnvironment(gym.Env):\n",
    "    def __init__(self,assets_names_list,assets_data_list,fee,initial_capital=100000,look_back_window=50,max_steps=200):\n",
    "        super(PortfolioEnvironment,self).__init__()\n",
    "        '''\n",
    "        assets_names_list: list with the ticker of each security\n",
    "        assets_data_list: list of pandas dataframes with the data of each security, must have the same length as assets_names_list and the first column of each dataframe must have the price of the asset\n",
    "        fee: porcentage of operating fee, with decimal, ie 0.1 is equal to 10% fee\n",
    "        initial_capital: amount of cash at the beginning\n",
    "        look_back_window: amount of periods to look back while executing a step\n",
    "        steps: maximum number of possible steps\n",
    "        '''\n",
    "        self.buffer = PortfolioBuffer(assets_names_list,np.array(list(map(lambda x: x.to_numpy(),assets_data_list))),look_back_window)\n",
    "        self.fee = fee\n",
    "        self.f = buffer.shape[2]\n",
    "        self.n = look_back_window\n",
    "        self.m = buffer.shape[0]\n",
    "        self.max_steps = max_steps\n",
    "        self.current_steps = 0\n",
    "        self.initial_capital = initial_capital\n",
    "        \n",
    "        self.action_space = gym.spaces.Box(low=0.0,high=2.0,shape=(self.m,),dtype=np.float16)\n",
    "        self.observation_space = gym.spaces.Box(low=0,high=1,shape=(self.f,self.n,self.m),dtype=np.float16)\n",
    "        \n",
    "        #self.weights = np.resize(np.array([1.0]+[0.0]*(self.m-1)),(self.n,self.m))\n",
    "        self.weights = np.array([1.0]+[0.0]*(self.m-1))\n",
    "        self.portfolio_value = 1.0\n",
    "        \n",
    "    def _buy(self,index,price,amount):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _sell(self,index,price,amount):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def _price_relative_vector(self):\n",
    "        '''\n",
    "        returns a matrix with the division of each assets value by the previous one\n",
    "        '''\n",
    "        #Toma el tensor X que tiene los precios, agarra solo el precio de cierre y calcula las diferencias\n",
    "        #Se seleccionan todos, los activos en todos los periodos pero solo la columna 0 que corresponde al precio de cierre\n",
    "        prices = self.buffer.get_batch()[:,:,0].T\n",
    "        prices_diff = prices[:-1]/prices[1:]\n",
    "        return prices_diff\n",
    "        \n",
    "    def _weights_at_end_of_period(self):\n",
    "        '''\n",
    "        returns a vector with the weights of the portfolio after the new prices but before taking any action\n",
    "        '''\n",
    "        #Se toma el ultimo cambio de precios conocido yt\n",
    "        y = self._price_relative_vector()[-1]\n",
    "        return np.multiply(y,self.weights)/np.dot(y,self.weights)\n",
    "    \n",
    "    def _operation_cost(self,weights):\n",
    "        '''\n",
    "        weights: vector with the new weights provided by the actor\n",
    "        returns a scalar value with the cost of doing the buy/sell operations needed to get to those weights\n",
    "        '''\n",
    "        w_prime = self._weights_at_end_of_period()[1:]\n",
    "        return self.fee * np.sum(np.abs(weights[1:]-w_prime))\n",
    "    \n",
    "    def _portfolio_value_after_operation(self,weights):\n",
    "        '''\n",
    "        weights: vector with the new weights provided by the actor\n",
    "        returns a scalar with the new value of the portfolio after doing the buy/sell operations needed to get to those weights\n",
    "        '''\n",
    "        c = self._operation_cost(weights)\n",
    "        p0 = self.portfolio_value\n",
    "        y = self._price_relative_vector()[-1]\n",
    "        w = self.weights\n",
    "        return p0 * (1 - c) * np.dot(y, w)\n",
    "    \n",
    "    def _portfolio_return_rate(self):\n",
    "        mu = self._transaction_remainder_factor()\n",
    "        y = self._price_relative_vector()[-1]\n",
    "        w = self.weights\n",
    "        return np.dot(mu*y,w) - 1\n",
    "    \n",
    "    def _portfolio_log_return_rate(self):\n",
    "        mu = self._transaction_remainder_factor()\n",
    "        y = self._price_relative_vector()[-1]\n",
    "        w = self.weights\n",
    "        return np.log(np.dot(mu*y,w))\n",
    "\n",
    "        \n",
    "    def _next_observation(self):\n",
    "        obs = self.buffer.get_next_batch()\n",
    "        return obs\n",
    "            \n",
    "\n",
    "    def _calculate_reward(self):\n",
    "        reward = -1\n",
    "        return reward\n",
    "    \n",
    "    def step(self, action):\n",
    "        \n",
    "        p1 = self._portfolio_value_after_operation(action)\n",
    "        self.weights = action\n",
    "        \n",
    "        \n",
    "        reward = self._calculate_reward()\n",
    "        \n",
    "        self.portfolio_value = p1\n",
    "        done = 0 if self.buffer.length > self.current_step and self.current_step<self.max_steps else 1 \n",
    "        info = {}\n",
    "        self.current_step += 1\n",
    "        obs = self._next_observation()\n",
    "        \n",
    "        return obs, reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        self.weights = np.array([1.0]+[0.0]*(self.m-1))\n",
    "        self.portfolio_value = 1.0\n",
    "        self.buffer.reset()\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe424c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_tf_base",
   "language": "python",
   "name": "neural_tf_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
